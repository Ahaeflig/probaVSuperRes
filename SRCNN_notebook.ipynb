{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an SRCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "\n",
    "# Import data loader\n",
    "from data_loader import MultipleDataLoader\n",
    "\n",
    "# Import model\n",
    "from SRCNN import SRCNN\n",
    "\n",
    "from training_helpers import clearMSE_metric, compute_loss\n",
    "\n",
    "from supreshelper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The input to our model is composed of the 4 most visible LR images combined with the median LR hence the number of channel is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_channels = 5\n",
    "data_dir = \"DataTFRecords/\"\n",
    "DataLoader = MultipleDataLoader(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We define the tf data object with proper properties for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "# List tfrecords files\n",
    "train_files = glob(data_dir +  \"train/*/*/multiple.tfrecords\")\n",
    "    \n",
    "# Create a tf dataset\n",
    "train_dataset = tf.data.TFRecordDataset(train_files)\n",
    "\n",
    "# Map each file to the parsing funciton, enabling data augmentation\n",
    "train_dataset = train_dataset.map(lambda x: DataLoader.parse_multiple_fixed(x, augment=True, num_lrs = lr_channels), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# reshuffle_each_iteration works only when combined with repeat\n",
    "train_dataset = train_dataset.repeat()\n",
    "train_dataset = train_dataset.shuffle(len(train_files))\n",
    "\n",
    "# Set the batch size\n",
    "train_dataset = train_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the SRCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRCNN(channel_dim=lr_channels, include_batch_norm = False).model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define initial learning rate and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define call back to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"Model/SRCNN/{epoch:02d}.hdf5\"\n",
    "os.makedirs(\"Model/SRCNN/\", exist_ok=True)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='train_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, compute_loss, metrics=[clearMSE_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "290/290 [==============================] - 226s 778ms/step - loss: 0.2575 - clearMSE_metric: 0.0057\n",
      "Epoch 2/30\n",
      "290/290 [==============================] - 218s 752ms/step - loss: 0.0328 - clearMSE_metric: 5.2070e-04\n",
      "Epoch 3/30\n",
      "290/290 [==============================] - 218s 752ms/step - loss: 0.0274 - clearMSE_metric: 5.0462e-04\n",
      "Epoch 4/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0263 - clearMSE_metric: 4.5124e-04\n",
      "Epoch 5/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0243 - clearMSE_metric: 4.8251e-04\n",
      "Epoch 6/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0249 - clearMSE_metric: 5.0406e-04\n",
      "Epoch 7/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0272 - clearMSE_metric: 5.1596e-04\n",
      "Epoch 8/30\n",
      "290/290 [==============================] - 218s 753ms/step - loss: 0.0223 - clearMSE_metric: 4.7342e-04\n",
      "Epoch 9/30\n",
      "290/290 [==============================] - 218s 752ms/step - loss: 0.0219 - clearMSE_metric: 4.4904e-04\n",
      "Epoch 10/30\n",
      "290/290 [==============================] - 218s 752ms/step - loss: 0.0228 - clearMSE_metric: 4.6542e-04\n",
      "Epoch 11/30\n",
      "290/290 [==============================] - 218s 752ms/step - loss: 0.0229 - clearMSE_metric: 4.7614e-04\n",
      "Epoch 12/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0220 - clearMSE_metric: 4.6592e-04\n",
      "Epoch 13/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0230 - clearMSE_metric: 4.7163e-04\n",
      "Epoch 14/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0223 - clearMSE_metric: 4.5109e-04\n",
      "Epoch 15/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0226 - clearMSE_metric: 4.3706e-04\n",
      "Epoch 16/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0236 - clearMSE_metric: 5.0864e-04\n",
      "Epoch 17/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0210 - clearMSE_metric: 4.5565e-04\n",
      "Epoch 18/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0214 - clearMSE_metric: 4.5426e-04\n",
      "Epoch 19/30\n",
      "290/290 [==============================] - 218s 753ms/step - loss: 0.0219 - clearMSE_metric: 4.2675e-04\n",
      "Epoch 20/30\n",
      "290/290 [==============================] - 218s 752ms/step - loss: 0.0220 - clearMSE_metric: 4.9995e-04\n",
      "Epoch 21/30\n",
      "290/290 [==============================] - 218s 752ms/step - loss: 0.0208 - clearMSE_metric: 4.6052e-04\n",
      "Epoch 22/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0228 - clearMSE_metric: 4.7702e-04\n",
      "Epoch 23/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0204 - clearMSE_metric: 4.5651e-04\n",
      "Epoch 24/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0214 - clearMSE_metric: 4.3303e-04\n",
      "Epoch 25/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0226 - clearMSE_metric: 4.8493e-04\n",
      "Epoch 26/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0212 - clearMSE_metric: 4.5047e-04\n",
      "Epoch 27/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0205 - clearMSE_metric: 4.7568e-04\n",
      "Epoch 28/30\n",
      "290/290 [==============================] - 218s 751ms/step - loss: 0.0210 - clearMSE_metric: 4.4833e-04\n",
      "Epoch 29/30\n",
      "290/290 [==============================] - 218s 752ms/step - loss: 0.0222 - clearMSE_metric: 4.5894e-04\n",
      "Epoch 30/30\n",
      "290/290 [==============================] - 218s 752ms/step - loss: 0.0215 - clearMSE_metric: 4.8742e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6030046f98>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_dataset, steps_per_epoch=len(train_files) / batch_size, epochs=30, use_multiprocessing=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute score on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_records = glob(data_dir +  \"train/*/*/multiple.tfrecords\")\n",
    "train_scenes = glob(data_dir +  \"train/*/*/\")\n",
    "    \n",
    "train_score = tf.data.TFRecordDataset(train_records)\n",
    "train_score = train_score.map(lambda x: DataLoader.parse_multiple_fixed(x, augment=False, num_lrs = lr_channels))\n",
    "# reshuffle_each_iteration works only for the repeat operation\n",
    "train_score = train_score.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "i = 0\n",
    "for lrs, hr in train_score:\n",
    "    sr = model(lrs)\n",
    "    scores.append(score_image_fast(sr[0][:,:,0].numpy(), train_scenes[i]))\n",
    "    i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0306669966571653\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
